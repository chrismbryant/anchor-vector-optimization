{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anchor-based multi-class classification\n",
    "\n",
    "* p anchors per class\n",
    "* k classes\n",
    "* n features\n",
    "* m examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 5, 5000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = 5\n",
    "k = 10\n",
    "n = 300\n",
    "m = 5000\n",
    "\n",
    "A = np.random.randn(k, p, n)\n",
    "X = np.random.randn(n, m)\n",
    "np.dot(A, X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function transpose in module tensorflow.python.ops.array_ops:\n",
      "\n",
      "transpose(a, perm=None, name='transpose', conjugate=False)\n",
      "    Transposes `a`. Permutes the dimensions according to `perm`.\n",
      "    \n",
      "    The returned tensor's dimension i will correspond to the input dimension\n",
      "    `perm[i]`. If `perm` is not given, it is set to (n-1...0), where n is\n",
      "    the rank of the input tensor. Hence by default, this operation performs a\n",
      "    regular matrix transpose on 2-D input Tensors. If conjugate is True and\n",
      "    `a.dtype` is either `complex64` or `complex128` then the values of `a`\n",
      "    are conjugated and transposed.\n",
      "    \n",
      "    For example:\n",
      "    \n",
      "    ```python\n",
      "    x = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
      "    tf.transpose(x)  # [[1, 4]\n",
      "                     #  [2, 5]\n",
      "                     #  [3, 6]]\n",
      "    \n",
      "    # Equivalently\n",
      "    tf.transpose(x, perm=[1, 0])  # [[1, 4]\n",
      "                                  #  [2, 5]\n",
      "                                  #  [3, 6]]\n",
      "    \n",
      "    # If x is complex, setting conjugate=True gives the conjugate transpose\n",
      "    x = tf.constant([[1 + 1j, 2 + 2j, 3 + 3j],\n",
      "                     [4 + 4j, 5 + 5j, 6 + 6j]])\n",
      "    tf.transpose(x, conjugate=True)  # [[1 - 1j, 4 - 4j],\n",
      "                                     #  [2 - 2j, 5 - 5j],\n",
      "                                     #  [3 - 3j, 6 - 6j]]\n",
      "    \n",
      "    # 'perm' is more useful for n-dimensional tensors, for n > 2\n",
      "    x = tf.constant([[[ 1,  2,  3],\n",
      "                      [ 4,  5,  6]],\n",
      "                     [[ 7,  8,  9],\n",
      "                      [10, 11, 12]]])\n",
      "    \n",
      "    # Take the transpose of the matrices in dimension-0\n",
      "    # (this common operation has a shorthand `matrix_transpose`)\n",
      "    tf.transpose(x, perm=[0, 2, 1])  # [[[1,  4],\n",
      "                                     #   [2,  5],\n",
      "                                     #   [3,  6]],\n",
      "                                     #  [[7, 10],\n",
      "                                     #   [8, 11],\n",
      "                                     #   [9, 12]]]\n",
      "    ```\n",
      "    \n",
      "    Args:\n",
      "      a: A `Tensor`.\n",
      "      perm: A permutation of the dimensions of `a`.\n",
      "      name: A name for the operation (optional).\n",
      "      conjugate: Optional bool. Setting it to `True` is mathematically equivalent\n",
      "        to tf.conj(tf.transpose(input)).\n",
      "    \n",
      "    Returns:\n",
      "      A transposed `Tensor`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.transpose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_mini_batches(X_train, Y_train, minibatch_size, seed):\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    (n, m) = X_train.shape\n",
    "    indices = np.array([i for i in range(n)])\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    minibatches = []\n",
    "    i = 0\n",
    "    \n",
    "    while i < m:\n",
    "        \n",
    "        minibatches.append((X_train[:, i:i+minibatch_size], Y_train[:, i:i+minibatch_size]))\n",
    "        i += minibatch_size\n",
    "    \n",
    "    return minibatches\n",
    "\n",
    "def one_hot():\n",
    "    \n",
    "    pass\n",
    "\n",
    "def create_placeholders(n, k):\n",
    "    \n",
    "    X = tf.placeholder(tf.float32, shape = [n, None], name = \"X\")\n",
    "    Y = tf.placeholder(tf.float32, shape = [k, None], name = \"Y\")\n",
    "    \n",
    "    return X, Y\n",
    "\n",
    "def initialize_params(p, k, n):\n",
    "    \n",
    "    # p anchors\n",
    "    # k classes\n",
    "    # n features\n",
    "    \n",
    "    A = tf.get_variable(\"A\", [k, p, n], dtype = tf.float32, initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    w = tf.get_variable(\"w\", [k, 1], dtype = tf.float32, initializer = tf.zeros_initializer())\n",
    "    b = tf.get_variable(\"b\", [k, 1], dtype = tf.float32, initializer = tf.zeros_initializer())\n",
    "    \n",
    "    params = {\n",
    "        \"A\": A,\n",
    "        \"w\": w,\n",
    "        \"b\": b\n",
    "    }\n",
    "                        \n",
    "    return params\n",
    "\n",
    "def forward_propagate(X, params):\n",
    "\n",
    "    # A.shape = (k, p, n)\n",
    "    # X.shape = (n, m)\n",
    "    # w.shape = (k, 1)\n",
    "    # b.shape = (k, 1)\n",
    "    \n",
    "    A = params[\"A\"]\n",
    "    w = params[\"w\"]\n",
    "    b = params[\"b\"]\n",
    "    \n",
    "    p = tf.shape(A)[0]\n",
    "    k = tf.shape(A)[2]\n",
    "    m = tf.shape(X)[1]\n",
    "    \n",
    "    norm_A = tf.reshape(tf.norm(A, axis = 1), (p, 1, k))\n",
    "    norm_X = tf.reshape(tf.norm(X, axis = 0), (1, m))\n",
    "    norm = tf.matmul(norm_A, norm_X)\n",
    "    \n",
    "    sim = tf.divide(tf.matmul(A, X), norm) # shape = (k, p, m)\n",
    "    dist = 1 - sim\n",
    "    \n",
    "    D = tf.reshape(tf.reduce_prod(dist, axis = 1), (k, m)) # shape = (k, m)\n",
    "    H = tf.softmax(tf.matmul(tf.transpose(w), D) + b) # shape = (1, m)\n",
    "    \n",
    "    return H\n",
    "\n",
    "def get_cost(Y, H, epsilon = 0.0001):\n",
    "    \n",
    "    # Y.shape = (k, m)\n",
    "    # H.shape = (k, m)\n",
    "    \n",
    "    m = tf.cast(tf.shape(Y)[1], \"float32\")\n",
    "    L = - tf.reduce_sum(Y * tf.log(tf.maximum(H, epsilon)), axis = 0)\n",
    "    cost = 1/m * tf.reduce_sum(L)\n",
    "    \n",
    "    return cost\n",
    "\n",
    "def get_A_reg(A, q=0, epsilon = 0.0001):\n",
    "    \n",
    "    # A.shape = (k, p, n)\n",
    "    \n",
    "    if q == 0:\n",
    "        return 0\n",
    "    \n",
    "    (k, p, n) = tf.shape(A)\n",
    "    \n",
    "    norm_A = tf.reshape(tf.norm(A, axis = 2), (k, p, 1))\n",
    "    norm = tf.matmul(norm_A, tf.transpose(norm_A, perm = [0, 2, 1])) # shape = (k, p, p)\n",
    "    \n",
    "    sim = tf.divide(tf.matmul(A, tf.transpose(A, perm = [0, 2, 1])), norm)\n",
    "    dist = tf.maximum(1 - sim, epsilon)\n",
    "    \n",
    "    energy = tf.reduce_sum(q**2 / dist)\n",
    "    \n",
    "    return energy\n",
    "\n",
    "def get_w_reg(w, c):\n",
    "    \n",
    "    pass\n",
    "\n",
    "# ##### -------------------------------------------------------- #####\n",
    "\n",
    "# def model(X_train, \n",
    "#           Y_train, \n",
    "#           X_test, \n",
    "#           Y_test, \n",
    "#           k = 4,\n",
    "#           q = 0,\n",
    "#           learning_rate = 0.0001,\n",
    "#           num_epochs = 1500, \n",
    "#           minibatch_size = 32, \n",
    "#           print_cost = True):\n",
    "    \n",
    "#     # X_train.shape = (n_x, m)\n",
    "#     # Y_train.shape = (1, m)\n",
    "    \n",
    "#     tf.reset_default_graph()\n",
    "    \n",
    "#     tf.set_random_seed(1)\n",
    "#     seed = 2\n",
    "    \n",
    "#     (n_x, m) = X_train.shape\n",
    "#     n_y = Y_train.shape[0]\n",
    "#     costs = []\n",
    "    \n",
    "#     X, Y = create_placeholders(n_x, n_y)\n",
    "#     params = initialize_params(k, n_x)\n",
    "#     H = forward_propagate(X, params)\n",
    "#     J = get_cost(Y, H) + get_reg(params[\"A\"], q = q)\n",
    "    \n",
    "#     optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(J)\n",
    "\n",
    "#     init = tf.global_variables_initializer()\n",
    "    \n",
    "#     with tf.Session() as sess:\n",
    "        \n",
    "#         sess.run(init)\n",
    "        \n",
    "#         for epoch in range(num_epochs):\n",
    "\n",
    "#             epoch_cost = 0\n",
    "#             num_minibatches = int(m / minibatch_size)\n",
    "#             seed += 1\n",
    "#             minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
    "            \n",
    "#             for minibatch in minibatches:\n",
    "\n",
    "#                 (minibatch_X, minibatch_Y) = minibatch\n",
    "#                 _ , minibatch_cost = sess.run([optimizer, J], feed_dict={X: minibatch_X, Y: minibatch_Y})\n",
    "#                 epoch_cost += minibatch_cost / num_minibatches\n",
    "            \n",
    "#             if print_cost == True and epoch % 200 == 0:\n",
    "#                 print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
    "#             if print_cost == True and epoch % 5 == 0:\n",
    "#                 costs.append(epoch_cost)\n",
    "                \n",
    "#         plt.plot(np.squeeze(costs))\n",
    "#         plt.ylabel('cost')\n",
    "#         plt.xlabel('iterations (per tens)')\n",
    "#         plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "#         plt.show()\n",
    "\n",
    "#         params = sess.run(params)\n",
    "#         print(\"Training complete.\")\n",
    "        \n",
    "#         pred = sess.run(H, feed_dict = {X: X_test})\n",
    "        \n",
    "#         return pred, params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
